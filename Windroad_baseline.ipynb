{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc7aacf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] 지정된 파일을 찾을 수 없습니다: 'windpath'\n",
      "D:\\dvc\\windpath\\12_sample\n",
      "[WinError 2] 지정된 파일을 찾을 수 없습니다: '12_sample'\n",
      "D:\\dvc\\windpath\\12_sample\n",
      "(1200, 1500, 2)\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from osgeo import gdal\n",
    "\n",
    "%cd windpath\n",
    "%cd 12_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "545411fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " lstm_input (InputLayer)        [(None, 9, 1200, 15  0           []                               \n",
      "                                00, 2)]                                                           \n",
      "                                                                                                  \n",
      " image_input (InputLayer)       [(None, 1200, 1500,  0           []                               \n",
      "                                 2)]                                                              \n",
      "                                                                                                  \n",
      " conv_lstm2d_5 (ConvLSTM2D)     (None, 9, 1200, 150  39296       ['lstm_input[0][0]']             \n",
      "                                0, 32)                                                            \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 1200, 1500,   608         ['image_input[0][0]']            \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " flatten_11 (Flatten)           (None, 518400000)    0           ['conv_lstm2d_5[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_10 (Flatten)           (None, 57600000)     0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " int_input (InputLayer)         [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 1)            518400001   ['flatten_11[0][0]']             \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 1)            57600001    ['flatten_10[0][0]']             \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 1)            4           ['int_input[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 3)            0           ['dense_16[0][0]',               \n",
      "                                                                  'dense_15[0][0]',               \n",
      "                                                                  'dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " output_layer (Dense)           (None, 225000)       900000      ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)            (None, 300, 375, 2)  0           ['output_layer[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_11 (Conv2DTra  (None, 600, 750, 32  608        ['reshape_5[0][0]']              \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_12 (Conv2DTra  (None, 1200, 1500,   578        ['conv2d_transpose_11[0][0]']    \n",
      " nspose)                        2)                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 576,941,096\n",
      "Trainable params: 576,941,096\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, ConvLSTM2D, Dense, Flatten, Concatenate,Reshape, BatchNormalization, UpSampling2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "time_steps = 9\n",
    "width = 1500\n",
    "height = 1200\n",
    "channels = 2\n",
    "\n",
    "# Terrain, landuse 이미지 데이터 입력\n",
    "image_input = Input(shape=(height,width, channels), name ='image_input')\n",
    "\n",
    "# CNN\n",
    "cnn_branch = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')(image_input)\n",
    "cnn_branch = Flatten()(cnn_branch)\n",
    "cnn_branch = Dense(1, activation='relu')(cnn_branch)\n",
    "\n",
    "# uz,vz 시계열 이미지 입력 레이어\n",
    "lstm_input = Input(shape=(time_steps,height,width, channels), name='lstm_input')\n",
    "\n",
    "# LSTM\n",
    "lstm_branch = ConvLSTM2D(filters=32, kernel_size=(3, 3), padding='same', return_sequences=True)(lstm_input)\n",
    "lstm_branch = Flatten()(lstm_branch)\n",
    "lstm_branch = Dense(1, activation='relu')(lstm_branch)\n",
    "\n",
    "# 지역풍 풍속, 높이, 풍향 정수 데이터 입력 레이어\n",
    "int_input = Input(shape=(3,), name='int_input')\n",
    "\n",
    "# 정수 분기\n",
    "mlp_branch = Dense(1, activation='relu')(int_input)\n",
    "\n",
    "# 결합\n",
    "merged_branch = Concatenate()([lstm_branch,cnn_branch, mlp_branch])\n",
    "\n",
    "# conv2dTranspose\n",
    "mid_layer = Dense(225000, activation='linear', name='output_layer')(merged_branch)\n",
    "mid_layer = Reshape((300, 375, 2))(mid_layer)\n",
    "mid_layer = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same')(mid_layer)\n",
    "output_layer = Conv2DTranspose(2, (3, 3), strides=(2, 2), padding='same')(mid_layer)\n",
    "\n",
    "# 모델 생성\n",
    "inputs = [image_input,lstm_input, int_input]\n",
    "model = Model(inputs=inputs, outputs=output_layer)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a6112f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nearly_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\\nhistory = model.fit(x=[X1, X2, X3], y=Y, validation_split=0.2, epochs=50, callbacks=[early_stop])\\n\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "X1 = [] # terrain, landuse 이미지\n",
    "X2 = []   # uz,vz 시계열이미지\n",
    "X3 = []    # 지역풍 높이, 풍속 ,풍향 입력 데이터\n",
    "Y = []   # Output data uz,vz 시계열 이미지\n",
    "path_prefix = \"klam21_\"\n",
    "for i in range(1, 2):\n",
    "  for h in range(1, 3):\n",
    "    for s in range(0,6):\n",
    "      for d in range(0, 360, 60):\n",
    "        path = path_prefix + \"0000\" +\"{:02d}\".format(i) +\"_R010_H0\"+ str(h) +\".0_S00\"+str(s)+\".00_D\"+\"{:003d}\".format(d)\n",
    "        landuse = np.loadtxt(path +'/landuse.txt', delimiter = ' ', skiprows = 6, dtype = 'int')\n",
    "        terrain = np.loadtxt(path +'/terrain.txt', delimiter = ' ', skiprows = 6, dtype = 'int')\n",
    "        stacked_uv = np.dstack((uz,vz))\n",
    "        X1.append(stacked_uv)\n",
    "        X3.append((h,s,d))\n",
    "        time_images = []\n",
    "        for j in range(360, 3960, 360):\n",
    "            uz = np.loadtxt(path+'/result/'+\"0000\" +\"{:02d}\".format(i) +\"_R010_H0\"+ str(h) +\".0_S00\"+str(s)+\".00_D\"+\"{:003d}\".format(d)+'_uz00'+\"{:04d}\".format(j)+'.dw', skiprows = 8, dtype = 'int', encoding='latin-1')\n",
    "            vz = np.loadtxt(path+'/result/'+\"0000\" +\"{:02d}\".format(i) +\"_R010_H0\"+ str(h) +\".0_S00\"+str(s)+\".00_D\"+\"{:003d}\".format(d)+'_vz00'+\"{:04d}\".format(j)+'.dw', skiprows = 8, dtype = 'int', encoding='latin-1')\n",
    "            stacked_uv = np.dstack((uz,vz))\n",
    "            if j == 3600:\n",
    "                Y.append(stacked_uv)\n",
    "            else :\n",
    "                time_images.append(stacked_uv)\n",
    "        time_images = np.array(time_images)\n",
    "        X2.append(time_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd8f8bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 1200, 1500, 2)\n"
     ]
    }
   ],
   "source": [
    "X1 = np.array(X1)\n",
    "X2 = np.array(X2)\n",
    "X3 = np.array(X3)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6558d767",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 9, 1200, 1500, 2)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b7bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = model.fit(x=[X1, X2, X3], y=Y, validation_split=0.2, epochs=50, callbacks=[early_stop])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
