{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc7aacf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\dvc\\windpath\n",
      "D:\\dvc\\windpath\\12_sample\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from osgeo import gdal\n",
    "\n",
    "%cd windpath\n",
    "%cd 12_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545411fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import ConvLSTM2D, Dense, Flatten\n",
    "\n",
    "time_steps = 9\n",
    "width = 1500\n",
    "height = 1200\n",
    "channels = 7\n",
    "\n",
    "model = Sequential([\n",
    "    keras.Input(shape=(None,channels,height,width)),\n",
    "    layers.ConvLSTM2D(filters=300, kernel_size=(3, 3), padding=\"same\", return_sequences=True),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ConvLSTM2D(filters=100, kernel_size=(3, 3), padding=\"same\", return_sequences=True),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ConvLSTM2D(filters=50, kernel_size=(3, 3), padding=\"same\", return_sequences=True),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv3D(filters=1,kernel_size=(3,3,3),activation=\"sigmoid\",padding=\"same\"),\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adadelta', loss='mse', metrics=['r2'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6112f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "path_prefix = \"klam21_\"\n",
    "for i in range(1, 2):\n",
    "  for h in range(1, 3):\n",
    "    for s in range(0,6):\n",
    "      for d in range(0, 360, 60):\n",
    "        height = np.full((1200,1500),h)\n",
    "        speed = np.full((1200,1500), s)\n",
    "        direction = np.full((1200,1500),d)\n",
    "        path = path_prefix + \"0000\" +\"{:02d}\".format(i) +\"_R010_H0\"+ str(h) +\".0_S00\"+str(s)+\".00_D\"+\"{:003d}\".format(d)\n",
    "        landuse = np.loadtxt(path +'/landuse.txt', delimiter = ' ', skiprows = 6, dtype = 'int')\n",
    "        terrain = np.loadtxt(path +'/terrain.txt', delimiter = ' ', skiprows = 6, dtype = 'int')\n",
    "        for j in range(360, 3960, 360):\n",
    "            uz = np.loadtxt(path+'/result/'+\"0000\" +\"{:02d}\".format(i) +\"_R010_H0\"+ str(h) +\".0_S00\"+str(s)+\".00_D\"+\"{:003d}\".format(d)+'_uz00'+\"{:04d}\".format(j)+'.dw', skiprows = 8, dtype = 'int', encoding='latin-1')\n",
    "            vz = np.loadtxt(path+'/result/'+\"0000\" +\"{:02d}\".format(i) +\"_R010_H0\"+ str(h) +\".0_S00\"+str(s)+\".00_D\"+\"{:003d}\".format(d)+'_vz00'+\"{:04d}\".format(j)+'.dw', skiprows = 8, dtype = 'int', encoding='latin-1')\n",
    "            stacked_layer = np.dstack((uz,vz,landuse,terrain,direction,speed,height))\n",
    "            if j == 3600:\n",
    "                Y.append(stacked_layer)\n",
    "            else :\n",
    "                X.append(stacked_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6558d767",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 33.8 GiB for an array with shape (720, 1200, 1500, 7) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3344\\93465556.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 33.8 GiB for an array with shape (720, 1200, 1500, 7) and data type int32"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b7bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = model.fit(x=X, y=Y, validation_split=0.2, epochs=50, callbacks=[early_stop])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
